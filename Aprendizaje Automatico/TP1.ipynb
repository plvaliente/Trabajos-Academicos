{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1 \n",
    "### Clasificación sobre datos simulados. \n",
    "\n",
    "## Introducción\n",
    "Para este trabajo, hemos creado una función generadora de minions. Sobre cada minion, hemos medido 200 características que representan habilidades que poseen en distintas tareas (relacionadas al Mal).  \n",
    "\n",
    "El doctor Nefario ha ideado una fórmula para determinar si un minion es o no apto para concretar su plan para conquistar el mundo. De esta manera ha etiquetado más de 500 minions. Lamentablemente, ha perdido dicha fórmula y necesita seguir decidiendo si nuevos minions son o no aptos para su macabro plan.\n",
    "\n",
    "Es por esto que nuestro objetivo será construir clasificadores que estimen lo mejor posible la probabilidad de que nuevos minions sean o no aptos para concretar el plan de conquista y así facilitarle las cosas al doctor Nefario.\n",
    "\n",
    "Por otra parte, ya que el doctor Nefario tuvo problemas con equipos que sobreestiman sus resultados, decidió guardarse varias etiquetas extra que no compartirá con nadie, y que luego utilizará para elegir al mejor equipo, al cual contratará para (de una vez por todas) conquistar el mundo. \n",
    "\n",
    "\n",
    "En concreto:\n",
    "\n",
    "Tendrán disponible una matriz de datos $X$ de $500$ filas en donde cada fila $x^{(i)}$ representa un vector de $200$ características de cada instancia. Es decir, $\\textbf{x}^{(i)} = x_1^{(i)}, \\dots, x_{200}^{(i)}$ con $i$ entre $1$ y $500$. Además, tendrán y, un vector de $500$ posiciones con dos posibles valores: $True$ y $False$. \n",
    "\n",
    "Por otra parte, tendrán disponibles más instancias de evaluación $X_{competencia}$ sin las respectivas etiquetas que utilizaremos para evaluar sus resultados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREAMBULOS\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as  pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.svm\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.model_selection\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4914</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>1.2315</td>\n",
       "      <td>1.2429</td>\n",
       "      <td>1.5576</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1983</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>1.5375</td>\n",
       "      <td>-0.7727</td>\n",
       "      <td>-0.1401</td>\n",
       "      <td>2.0871</td>\n",
       "      <td>-0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.2749</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>-1.3108</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>-0.5503</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>-0.4478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2190</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>-0.6446</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-1.2374</td>\n",
       "      <td>-1.3291</td>\n",
       "      <td>-1.3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2243</td>\n",
       "      <td>-0.5710</td>\n",
       "      <td>-0.2712</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-1.0045</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>-1.4507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>-0.1989</td>\n",
       "      <td>-0.0393</td>\n",
       "      <td>-0.5866</td>\n",
       "      <td>2.2507</td>\n",
       "      <td>1.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5853</td>\n",
       "      <td>-0.8532</td>\n",
       "      <td>-0.2723</td>\n",
       "      <td>-0.5493</td>\n",
       "      <td>-2.9824</td>\n",
       "      <td>-0.1697</td>\n",
       "      <td>-0.0430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6488</td>\n",
       "      <td>-0.7363</td>\n",
       "      <td>-0.8866</td>\n",
       "      <td>-1.2717</td>\n",
       "      <td>-0.1493</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>-1.4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.4155</td>\n",
       "      <td>1.4187</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>-0.7993</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>-0.1796</td>\n",
       "      <td>-0.7140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1314</td>\n",
       "      <td>-0.4230</td>\n",
       "      <td>-0.2685</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>-1.2245</td>\n",
       "      <td>-1.9421</td>\n",
       "      <td>1.5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>-1.1980</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>-0.5494</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>1.2182</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>3.0034</td>\n",
       "      <td>-0.0344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.6246</td>\n",
       "      <td>-1.0590</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>-1.6657</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1075</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>-0.4229</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>-0.0808</td>\n",
       "      <td>-1.7054</td>\n",
       "      <td>-0.4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>-0.9023</td>\n",
       "      <td>-1.7792</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>-1.0090</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>-1.7513</td>\n",
       "      <td>-0.5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>1.7056</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>-0.8350</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-1.6642</td>\n",
       "      <td>2.5117</td>\n",
       "      <td>-0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>-0.6085</td>\n",
       "      <td>1.0845</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3121</td>\n",
       "      <td>-0.7630</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>-0.0902</td>\n",
       "      <td>-1.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6   ...       193  \\\n",
       "index                                                           ...             \n",
       "0      1.4914  0.1644  1.2315  1.2429  1.5576  0.0455  0.1302   ...   -1.1983   \n",
       "1     -0.2749  0.2780 -1.3108  0.6801 -0.5503  0.6359 -0.4478   ...    1.2190   \n",
       "2     -0.2243 -0.5710 -0.2712 -0.1328 -1.0045  0.9315 -1.4507   ...    0.9459   \n",
       "3      0.5853 -0.8532 -0.2723 -0.5493 -2.9824 -0.1697 -0.0430   ...    1.6488   \n",
       "4     -1.4155  1.4187  0.6027 -0.7993  0.2939 -0.1796 -0.7140   ...    1.1314   \n",
       "...       ...     ...     ...     ...     ...     ...     ...   ...       ...   \n",
       "495    0.2516  0.9375 -1.1980  0.4577  0.9287  0.5373  0.2476   ...    0.5829   \n",
       "496    0.6246 -1.0590  0.9491  0.2687  0.6610 -1.6657  0.3982   ...   -0.1075   \n",
       "497    0.2677  0.1802  0.7154  0.3542 -0.9023 -1.7792 -0.0121   ...    0.8491   \n",
       "498    0.1926  0.7834  1.7056  0.3418 -0.8350  0.4068  0.0495   ...   -0.0130   \n",
       "499    0.0427  0.4028 -0.6085  1.0845  0.1033  0.2698 -0.8598   ...   -0.3587   \n",
       "\n",
       "          194     195     196     197     198     199  \n",
       "index                                                  \n",
       "0     -0.0118  1.5375 -0.7727 -0.1401  2.0871 -0.8312  \n",
       "1     -0.3190 -0.6446 -0.0061 -1.2374 -1.3291 -1.3265  \n",
       "2      0.1430 -0.1989 -0.0393 -0.5866  2.2507  1.4925  \n",
       "3     -0.7363 -0.8866 -1.2717 -0.1493  0.2007 -1.4820  \n",
       "4     -0.4230 -0.2685  0.3045 -1.2245 -1.9421  1.5186  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "495   -0.5494  0.4607  1.2182  0.1025  3.0034 -0.0344  \n",
       "496    0.8993 -0.4229  0.3977 -0.0808 -1.7054 -0.4786  \n",
       "497    0.7469  0.2071 -1.0090  0.3317 -1.7513 -0.5397  \n",
       "498    0.1483  0.5019 -0.0020 -1.6642  2.5117 -0.0118  \n",
       "499   -0.3121 -0.7630  0.6525  0.6161 -0.0902 -1.0215  \n",
       "\n",
       "[500 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output\n",
       "index        \n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           1\n",
       "...       ...\n",
       "495         1\n",
       "496         0\n",
       "497         1\n",
       "498         0\n",
       "499         0\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      2.9702\n",
       "1      2.7920\n",
       "2      2.6905\n",
       "3      2.8091\n",
       "4      2.9823\n",
       "        ...  \n",
       "195    2.9109\n",
       "196    2.4942\n",
       "197    3.1804\n",
       "198    3.0034\n",
       "199    2.5107\n",
       "Length: 200, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0     -3.1722\n",
       "1     -2.4596\n",
       "2     -2.8834\n",
       "3     -3.7474\n",
       "4     -2.9987\n",
       "        ...  \n",
       "195   -2.5163\n",
       "196   -3.9278\n",
       "197   -2.4254\n",
       "198   -2.6234\n",
       "199   -2.8690\n",
       "Length: 200, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.9122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.4295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.8060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.0661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.4022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.0091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.2368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.9277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4499 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output\n",
       "index        \n",
       "501    0.9122\n",
       "502    0.4295\n",
       "503    0.6675\n",
       "504    0.8060\n",
       "505    0.0661\n",
       "...       ...\n",
       "4995   0.4022\n",
       "4996   0.0091\n",
       "4997   0.2368\n",
       "4998   0.1004\n",
       "4999   0.9277\n",
       "\n",
       "[4499 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carga de datos\n",
    "X = pd.read_csv(\"X.csv\", index_col=\"index\")\n",
    "y = pd.read_csv(\"y.csv\", index_col=\"index\", dtype=int)  # Cargamos los valores booleanos (True y False)\n",
    "                                                        # como números (1 y 0) para facilitar el manejo luego. \n",
    "    \n",
    "X_competencia = pd.read_csv(\"X_competencia1.csv\", index_col=\"index\")\n",
    "y_competencia_ejemplo = pd.read_csv(\"y_competencia_ejemplo.csv\", index_col=\"index\")\n",
    "\n",
    "display(X)\n",
    "display(y)\n",
    "\n",
    "#chequeo de escalas\n",
    "display(np.amax(X,axis=0))\n",
    "display(np.amin(X,axis=0))\n",
    "\n",
    "\n",
    "# Descomentar si quieren ver los datos para la competencia:\n",
    "# display(X_competencia) \n",
    "#display(y_competencia_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "### Separación de datos\n",
    "\n",
    "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. En este punto pedimos que evalúen cómo separar sus datos para desarrollo y para evaluación tomando en cuenta la competencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dev: (400, 200), y_dev: (400, 1) para desarrollo\n",
      "X_eval: (100, 200), y_eval: (100, 1) para evaluación\n",
      "Proporcion Aptos: 0.4575\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO 1. \n",
    "\n",
    "\n",
    "########################################################\n",
    "np.random.seed(1234)\n",
    "X_dev, X_eval, y_dev, y_eval = sklearn.model_selection.train_test_split(X, y, stratify=y, test_size = 1/5)\n",
    "\n",
    "# X_eval y_eval: son el heldout, separados usando la misma proporcion de malos y buenos, y shuffleando. DEF \n",
    "\n",
    "#########################################################\n",
    "\n",
    "\n",
    "print(\"X_dev: {}, y_dev: {} para desarrollo\".format(X_dev.shape, y_dev.shape))\n",
    "print(\"X_eval: {}, y_eval: {} para evaluación\".format(X_eval.shape, y_eval.shape))\n",
    "print(\"Proporcion Aptos:\", np.array(y_dev).sum()/np.array(y_dev).shape[0] )\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(np.array(y_dev))  # muestra un histograma para la distribución de y.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting\n",
    "\n",
    "Se decidio utilizar un 20% de los datos como conjunto de Held-Out. Se utlizó el argumento stratify=y para mantener la proporcion de categorías de y en el split. El conjunto Held-Out permanecerá incorrupto hasta el final del experimento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "### Construcción de modelos\n",
    "\n",
    "Para este punto, la tarea consiste en construir y evaluar modelos de tipo árbol de decisión, de manera de obtener una estimación realista de la performance de los mismos. \n",
    "\n",
    "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default. \n",
    "2. Estimar la performance del modelo utilizando K-fold cross validation con K = 5, con las métricas “Accuracy” y “ROC AUC”. Para ello, se pide medir la performance en cada partición tanto sobre el fold de validación como sobre los folds de entrenamiento. Luego, completar la primera tabla.\n",
    "3. Entrenar árboles de decisión para cada una de las siguientes combinaciones y completar la segunda tabla.\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA: Usar la implementación de árboles de decisión que realizaron para la guía de ejercicios de la materia. Adaptarla para que cumpla con la interfaz requerida por sklearn, asegurarse de que funcione con variables continuas y reproducir las tablas anteriores.   **\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutación</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8213</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.7294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8621</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>0.6345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>0.7266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8255</td>\n",
       "      <td>0.6709</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.7377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.5696</td>\n",
       "      <td>0.8701</td>\n",
       "      <td>0.6247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "Permutación                                                                   \n",
       "1                         0.8213                 0.6667              0.8806   \n",
       "2                         0.8621                 0.6296              0.8971   \n",
       "3                         0.8250                 0.6625              0.8807   \n",
       "4                         0.8255                 0.6709              0.8852   \n",
       "5                         0.8287                 0.5696              0.8701   \n",
       "\n",
       "             AUC ROC (validación)  \n",
       "Permutación                        \n",
       "1                          0.7294  \n",
       "2                          0.6345  \n",
       "3                          0.7266  \n",
       "4                          0.7377  \n",
       "5                          0.6247  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_training = []\n",
    "accuracies_validation = []\n",
    "aucs_training = []\n",
    "aucs_validation = []\n",
    "\n",
    "# Puede serles de utilidad tener a X_dev e y_dev como matrices de numpy directamente:\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO\n",
    "## Objetivo: accuracies_training, accuracies_validation, aucs_training y aucs_validation asignados\n",
    "\n",
    "# Hacer arbol\n",
    "# (Separar en KFold)\n",
    "# Iterar por cada fold: fitear arbol, calcular accuracies y aucs en training y validation y guardarlos\n",
    "\n",
    "arbol = DecisionTreeClassifier(max_depth=3)\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "#shufflea con el seed de arriba, manteniendo proporciones de datos por fold.\n",
    "scores = sklearn.model_selection.cross_validate(arbol, X_dev_np, y_dev_np, cv = cv,\n",
    "                                                scoring=['accuracy', 'roc_auc'], return_train_score=True)\n",
    "\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = scores['train_accuracy']     # cambiar por accuracies_training\n",
    "df[\"Accuracy (validación)\"] = scores['test_accuracy']   # cambiar por accuracies_validation\n",
    "df[\"AUC ROC (training)\"] = scores['train_roc_auc']      # cambiar por aucs_training\n",
    "df[\"AUC ROC (validación)\"] = scores['test_roc_auc']    # cambiar por aucs_validation\n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "#df.plot(kind=\"bar\")\n",
    "#plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 2 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura máxima</th>\n",
       "      <th>Criterio de evaluación de corte</th>\n",
       "      <th>AUC ROC promedio (training)</th>\n",
       "      <th>AUC ROC promedio (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>0.6906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.6442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.8606</td>\n",
       "      <td>0.7239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.6596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \\\n",
       "0             3                            Gini                       0.8827   \n",
       "1             5                            Gini                       0.9832   \n",
       "2     Inifinito                            Gini                       1.0000   \n",
       "3             3         Ganancia de Información                       0.8606   \n",
       "4             5         Ganancia de Información                       0.9692   \n",
       "5     Inifinito         Ganancia de Información                       1.0000   \n",
       "\n",
       "   AUC ROC promedio (validación)  \n",
       "0                         0.6906  \n",
       "1                         0.6442  \n",
       "2                         0.6265  \n",
       "3                         0.7239  \n",
       "4                         0.6596  \n",
       "5                         0.6162  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: resultados_training y resultados_validation asignadas\n",
    "#\n",
    "## Recomendamos seguir el siguiente esquema:\n",
    "# np.random.seed(SEED)\n",
    "# for criterio in [\"gini\", \"entropy\"]:\n",
    "#     for altura in [3, 5, None]:\n",
    "#         CODIGO AQUI.\n",
    "#         resultados_training.append( <RESULTADO_TRAINING> )\n",
    "#         resultados_validation.append( <RESULTADO_VALIDATION> )\n",
    "\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "    for altura in [3, 5, None]:\n",
    "        arbol = DecisionTreeClassifier(max_depth=altura, criterion=criterio)\n",
    "        np.random.seed(1234) # lo pongo aca para que todos tengan los mismos k-folds\n",
    "        cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True)\n",
    "        scores = sklearn.model_selection.cross_validate(arbol, X_dev_np, y_dev_np, cv = cv, \n",
    "                                                        scoring=['roc_auc'], return_train_score=True)\n",
    "        resultados_training.append( scores['train_roc_auc'].mean() )\n",
    "        resultados_validation.append( scores['test_roc_auc'].mean() )\n",
    "\n",
    "#########################################################\n",
    "\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation\n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##EXTRA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Comparación de algoritmos\n",
    "\n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje e hiperparámetros, de manera de buscar una performance óptima. Para este ejercicio es necesario que evalúen posibilidades utilizando la técnica de Grid Search. Como métrica de performance, usar siempre el área bajo la curva (AUC ROC) resultante de 5-fold cross-validation. \n",
    "\n",
    "Algoritmos a probar: KNN, árboles de decisión, LDA, Naive Bayes y SVM. Hiperparámetros: Revisar la documentación de cada uno para la búsqueda de combinaciones prometedoras.  \n",
    "\n",
    "Se pide generar un reporte que contenga: \n",
    "\n",
    "1. Una descripción de las distintas combinaciones consideradas y su performance asociada (las que consideren relevantes, con al menos la mejor combinación para cada algoritmo). \n",
    "\n",
    "1. Una breve explicación de los factores que creen que produjeron dicho resultado. \n",
    "\n",
    "En este punto evaluaremos tanto los hiperparámetros elegidos como las conclusiones relacionadas a por qué piensan que ciertos algoritmos funcionan mejor que otros para estos datos. \n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA**: Utilizar RandomizedSearchCV con rangos de parámetros que contengan a los utilizados en el GridSearch. Analizar si se encontraron mejores combinaciones de parámetros que no hayan sido tenidas en cuenta con el GridSearch y cuál fue la diferencia de tiempo de ejecución. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "\n",
    "def top_resultados(grid, top=10):\n",
    "    ## Si quieren, pueden utilizar esta función para imprimir las mejores combinaciones de su grid\n",
    "    print(\"Top {} combinaciones\".format(top))\n",
    "    df = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    df[\"mean_score_validation\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    df[\"mean_score_training\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "    display(df.sort_values(by=\"mean_score_validation\", ascending=False).head(top))\n",
    "\n",
    "########################################################\n",
    "## Objetivo: comparar y explorar distintas combinaciones de parámetros para los algoritmos importados arriba\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8166</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>0.8516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8161</td>\n",
       "      <td>0.8548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8141</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8119</td>\n",
       "      <td>0.8619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8112</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8107</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8042</td>\n",
       "      <td>0.8590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  p   weights  mean_score_validation  mean_score_training\n",
       "27           20  2  distance                 0.8172               1.0000\n",
       "25           20  1  distance                 0.8166               1.0000\n",
       "24           20  1   uniform                 0.8162               0.8516\n",
       "26           20  2   uniform                 0.8161               0.8548\n",
       "29           20  5  distance                 0.8141               1.0000\n",
       "28           20  5   uniform                 0.8119               0.8619\n",
       "21           15  2  distance                 0.8112               1.0000\n",
       "20           15  2   uniform                 0.8107               0.8570\n",
       "19           15  1  distance                 0.8048               1.0000\n",
       "18           15  1   uniform                 0.8042               0.8590"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.22203183174133\n"
     ]
    }
   ],
   "source": [
    "##### KNN PARAMETERS\n",
    "# n_neighbors Number of neighbors\n",
    "# p=1 Manhattan_distance\n",
    "# p=2 Euclidean_distance (l2) \n",
    "# p=!1 y 2 Minkowski_distance(p)\n",
    "# weights='uniform' All points in each neighborhood are weighted equally\n",
    "# weights='distance' Weight points by the inverse of their distance\n",
    "### como minkowski es la metrica default usando solo p puedo simular las otras mas usuales. \n",
    "### Los demas no los usamos porque son mas de eficiencia algoritmica que de aprendizaje.\n",
    "start = time. time()\n",
    "knn_grid_parameters = {\n",
    "    'n_neighbors': [1, 5, 10, 15, 20], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p':[1,2,5]\n",
    "}\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=knn_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8369</td>\n",
       "      <td>0.8472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.8369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8317</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>0.8495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8312</td>\n",
       "      <td>0.8381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8273</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8268</td>\n",
       "      <td>0.8406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  p   weights  mean_score_validation  mean_score_training\n",
       "8           100  1   uniform                 0.8369               0.8472\n",
       "9           100  1  distance                 0.8367               1.0000\n",
       "13          150  1  distance                 0.8325               1.0000\n",
       "7            50  2  distance                 0.8325               1.0000\n",
       "12          150  1   uniform                 0.8320               0.8369\n",
       "15          150  2  distance                 0.8317               1.0000\n",
       "6            50  2   uniform                 0.8316               0.8495\n",
       "14          150  2   uniform                 0.8312               0.8381\n",
       "11          100  2  distance                 0.8273               1.0000\n",
       "10          100  2   uniform                 0.8268               0.8406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.310601711273193\n"
     ]
    }
   ],
   "source": [
    "##### KNN ITERATION 1\n",
    "start = time. time()\n",
    "knn_grid_parameters = {\n",
    "    'n_neighbors': [10, 50, 100, 150], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p':[1,2]\n",
    "}\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=knn_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8382</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>0.8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8369</td>\n",
       "      <td>0.8472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8366</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.8534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  p   weights  mean_score_validation  mean_score_training\n",
       "12           80  1   uniform                 0.8382               0.8503\n",
       "13           80  1  distance                 0.8380               1.0000\n",
       "16           90  1   uniform                 0.8370               0.8490\n",
       "20          100  1   uniform                 0.8369               0.8472\n",
       "21          100  1  distance                 0.8367               1.0000\n",
       "17           90  1  distance                 0.8366               1.0000\n",
       "9            70  1  distance                 0.8325               1.0000\n",
       "7            60  2  distance                 0.8325               1.0000\n",
       "3            50  2  distance                 0.8325               1.0000\n",
       "6            60  2   uniform                 0.8320               0.8534"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.671769618988037\n"
     ]
    }
   ],
   "source": [
    "##### KNN ITERATION 2\n",
    "start=time. time()\n",
    "knn_grid_parameters = {\n",
    "    'n_neighbors': [50, 60, 70, 80, 90, 100], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p':[1,2]\n",
    "}\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=knn_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>0.8504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8393</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.8501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8389</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8389</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8382</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8381</td>\n",
       "      <td>0.8505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  p   weights  mean_score_validation  mean_score_training\n",
       "20           83  1   uniform                 0.8401               0.8504\n",
       "24           85  1   uniform                 0.8400               0.8503\n",
       "21           83  1  distance                 0.8393               1.0000\n",
       "16           81  1   uniform                 0.8392               0.8501\n",
       "25           85  1  distance                 0.8389               1.0000\n",
       "17           81  1  distance                 0.8389               1.0000\n",
       "12           80  1   uniform                 0.8382               0.8503\n",
       "28           87  1   uniform                 0.8381               0.8505\n",
       "13           80  1  distance                 0.8380               1.0000\n",
       "9            79  1  distance                 0.8378               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.028008937835693\n"
     ]
    }
   ],
   "source": [
    "##### KNN ITERATION 3\n",
    "start=time. time()\n",
    "knn_grid_parameters = {\n",
    "    'n_neighbors': [75, 57, 79, 80, 81, 83, 85, 87, 89, 90, 91, 93, 95], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p':[1,2]\n",
    "}\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=knn_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al iterar sobre la cantidad de vecinos para determinar el mejor modelo, encontramos un óptimo cercano a ochenta. Es un cuarto de la cantidad total de instancias de entrenamiento y parece ser suficiente para generalizar patrones.\n",
    "Asimismo, no parece haber mayores diferencias en el score de validación al ponderar por distancia y preferimos un algoritmo que no tenga un score de 1 en el training para evitar sobreajuste.\n",
    "No parece haber una estructura en los datos que requiera medir la distancia de manera no euclidiana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>0.8509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8371</td>\n",
       "      <td>0.8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8321</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8249</td>\n",
       "      <td>0.8314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8216</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8197</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8189</td>\n",
       "      <td>0.8369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neighbors  p   weights  mean_score_validation  mean_score_training\n",
       "6           59  2   uniform                 0.8510               0.8509\n",
       "0           55  3   uniform                 0.8371               0.8490\n",
       "3           72  3  distance                 0.8367               1.0000\n",
       "5           82  3  distance                 0.8322               1.0000\n",
       "4           85  3  distance                 0.8321               1.0000\n",
       "7           83  4   uniform                 0.8249               0.8314\n",
       "8           50  4  distance                 0.8218               1.0000\n",
       "9           90  4  distance                 0.8216               1.0000\n",
       "1           63  4   uniform                 0.8197               0.8333\n",
       "2           59  4   uniform                 0.8189               0.8369"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.79771590232849\n"
     ]
    }
   ],
   "source": [
    "#### KNN usando randomized search\n",
    "start=time. time()\n",
    "knn_rsearch_parameters = {\n",
    "    'n_neighbors': np.arange(50,100), \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p':np.arange(1,5)\n",
    "}\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=knn_rsearch_parameters, n_iter=10, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación entre grid y randomized search para KNN\n",
    "Utilizando el RandomSearch con 10 iteraciones llegamos a un óptimo de apenas mayor score de validación y con menos vecinos, de 59 en vez de 80, y con p=2. Cuando acotamos el rango de la iteracion 2 a la 3, descartamos estos valores más bajos de vecinos ya que habian dado mejor score vecinos más altos pero con p=1. Quizás debiéramos haber hecho dos categorías según el tipo de distancia y luego acotar el rango. Con el randomized search, se pudo barrer en un tiempo menor, un amplio rango de combinaciones sin tener que hacer iteraciones restringiendo el campo como hicimos en el grid search. El tiempo de ejecución es un 30% más en el caso del grid search respecto del randomized search si consideramos la suma de las cuatro iteraciones que hicimos en el grid search. La comparación más apropiada sería de un grid search con el mismo rango que el randomized search, pero da incluso mayor tiempo de ejecución. Es posible que hayamos tenido suerte con la randomización dado que con tan pocas iteraciones encontramos un mejor score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>gini</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7954</td>\n",
       "      <td>0.8798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>gini</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>0.8531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5475</th>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.8618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7898</td>\n",
       "      <td>0.8768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>gini</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>best</td>\n",
       "      <td>0.7890</td>\n",
       "      <td>0.8604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>gini</td>\n",
       "      <td>10.0</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>0.8719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>180</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.8147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7850</td>\n",
       "      <td>0.8225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7848</td>\n",
       "      <td>0.8711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6981</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7846</td>\n",
       "      <td>0.8945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     criterion  max_depth max_features  min_samples_leaf  min_samples_split  \\\n",
       "2923      gini       10.0         None                 2                 50   \n",
       "1967      gini        5.0         None                20                 20   \n",
       "5475   entropy        5.0          150                15                  2   \n",
       "3337      gini        NaN          180                15                 10   \n",
       "2588      gini       10.0          100                15                 70   \n",
       "2459      gini       10.0          150                15                 30   \n",
       "5415   entropy        5.0          180                35                 50   \n",
       "5863   entropy        5.0           50                15                 50   \n",
       "3971      gini        NaN         None                15                 30   \n",
       "6981   entropy       10.0         None                10                 30   \n",
       "\n",
       "     splitter  mean_score_validation  mean_score_training  \n",
       "2923   random                 0.7954               0.8798  \n",
       "1967   random                 0.7945               0.8531  \n",
       "5475   random                 0.7917               0.8618  \n",
       "3337   random                 0.7898               0.8768  \n",
       "2588     best                 0.7890               0.8604  \n",
       "2459   random                 0.7889               0.8719  \n",
       "5415   random                 0.7881               0.8147  \n",
       "5863   random                 0.7850               0.8225  \n",
       "3971   random                 0.7848               0.8711  \n",
       "6981   random                 0.7846               0.8945  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434.720956325531\n"
     ]
    }
   ],
   "source": [
    "##### Decision Tree Classifier (DT)\n",
    "start=time. time()\n",
    "dt_grid_parameters = {\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth':[3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10, 20, 30, 50, 70],\n",
    "    'min_samples_leaf': [1, 2, 5, 10, 15, 20, 25, 30, 35],\n",
    "    'max_features': ['sqrt', 'log2', 180, 150, 100, 75, 50, None]\n",
    "}\n",
    "\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid=dt_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>random</td>\n",
       "      <td>0.8010</td>\n",
       "      <td>0.8288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>0.8752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.8347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>0.8015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>0.8319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7823</td>\n",
       "      <td>0.8187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7816</td>\n",
       "      <td>0.8220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>best</td>\n",
       "      <td>0.7804</td>\n",
       "      <td>0.8294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7799</td>\n",
       "      <td>0.8469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>best</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.8903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     criterion  max_depth max_features  min_samples_leaf  min_samples_split  \\\n",
       "1709      gini          4          100                20                 15   \n",
       "2145      gini          4         None                10                  2   \n",
       "4421   entropy          4         None                20                  4   \n",
       "897       gini          3           50                20                  2   \n",
       "3799   entropy          4          150                25                  5   \n",
       "4113   entropy          4           75                25                  2   \n",
       "2629   entropy          3          150                10                  4   \n",
       "52        gini          3         sqrt                 5                  4   \n",
       "1677      gini          4          100                10                 15   \n",
       "4244   entropy          4           50                15                  4   \n",
       "\n",
       "     splitter  mean_score_validation  mean_score_training  \n",
       "1709   random                 0.8010               0.8288  \n",
       "2145   random                 0.7888               0.8752  \n",
       "4421   random                 0.7860               0.8347  \n",
       "897    random                 0.7843               0.8015  \n",
       "3799   random                 0.7840               0.8319  \n",
       "4113   random                 0.7823               0.8187  \n",
       "2629   random                 0.7816               0.8220  \n",
       "52       best                 0.7804               0.8294  \n",
       "1677   random                 0.7799               0.8469  \n",
       "4244     best                 0.7788               0.8903  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206.40586018562317\n"
     ]
    }
   ],
   "source": [
    "##### DT ITERATION 1\n",
    "start=time. time()\n",
    "dt_grid_parameters = {\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth':[3, 4],\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 3, 5, 10, 15, 20, 25, 30, 35],\n",
    "    'max_features': ['sqrt', 'log2', 150, 100, 75, 50, None]\n",
    "}\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid=dt_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>0.8007</td>\n",
       "      <td>0.8262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7915</td>\n",
       "      <td>0.8429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7822</td>\n",
       "      <td>0.8519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7801</td>\n",
       "      <td>0.8287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.7979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.8350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7774</td>\n",
       "      <td>0.8061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>0.8339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>best</td>\n",
       "      <td>0.7767</td>\n",
       "      <td>0.8548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>0.8045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     criterion  max_depth  max_features  min_samples_leaf  min_samples_split  \\\n",
       "2220   entropy          3           100                 7                  2   \n",
       "3556   entropy          4            90                13                 28   \n",
       "1098      gini          4           100                 1                 30   \n",
       "1584      gini          4            80                15                  7   \n",
       "310       gini          3            90                13                 19   \n",
       "1532      gini          4            80                 9                 22   \n",
       "254       gini          3            90                 7                 25   \n",
       "1918      gini          4            60                11                 30   \n",
       "2853   entropy          3            70                15                 22   \n",
       "2316   entropy          3           100                15                 28   \n",
       "\n",
       "     splitter  mean_score_validation  mean_score_training  \n",
       "2220   random                 0.8007               0.8262  \n",
       "3556   random                 0.7915               0.8429  \n",
       "1098   random                 0.7822               0.8519  \n",
       "1584   random                 0.7801               0.8287  \n",
       "310    random                 0.7783               0.7979  \n",
       "1532   random                 0.7778               0.8350  \n",
       "254    random                 0.7774               0.8061  \n",
       "1918   random                 0.7771               0.8339  \n",
       "2853     best                 0.7767               0.8548  \n",
       "2316   random                 0.7759               0.8045  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190.30941939353943\n"
     ]
    }
   ],
   "source": [
    "##### DT ITERATION 2\n",
    "start=time. time()\n",
    "dt_grid_parameters = {\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'splitter': ['random', 'best'],\n",
    "    'max_depth':[3, 4],\n",
    "    'min_samples_split': [2, 3, 7, 9, 16, 19, 22, 25, 28, 30],\n",
    "    'min_samples_leaf': [1, 3, 5, 7, 9, 11, 13, 15, 17],\n",
    "    'max_features': [ 100, 90, 80, 70, 60, 50]\n",
    "}\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid=dt_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7993</td>\n",
       "      <td>0.8235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>0.8326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.8529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>0.7933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.8239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7842</td>\n",
       "      <td>0.8316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>0.8384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.8429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7830</td>\n",
       "      <td>0.8360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.7888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     criterion  max_depth  max_features  min_samples_leaf  min_samples_split  \\\n",
       "434       gini          4            90                15                 19   \n",
       "1704   entropy          4           100                17                  2   \n",
       "430       gini          4            90                14                 31   \n",
       "883       gini          3           100                13                 28   \n",
       "1857   entropy          4            95                16                 30   \n",
       "750       gini          4            80                15                 27   \n",
       "2158   entropy          4            85                15                 31   \n",
       "279       gini          4            95                15                 20   \n",
       "2021   entropy          4            90                17                 22   \n",
       "2680   entropy          3            90                 7                 21   \n",
       "\n",
       "     splitter  mean_score_validation  mean_score_training  \n",
       "434    random                 0.7993               0.8235  \n",
       "1704   random                 0.7901               0.8326  \n",
       "430    random                 0.7882               0.8529  \n",
       "883    random                 0.7880               0.7933  \n",
       "1857   random                 0.7864               0.8239  \n",
       "750    random                 0.7842               0.8316  \n",
       "2158   random                 0.7840               0.8384  \n",
       "279    random                 0.7833               0.8429  \n",
       "2021   random                 0.7830               0.8360  \n",
       "2680   random                 0.7820               0.7888  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.55314111709595\n"
     ]
    }
   ],
   "source": [
    "##### DT ITERATION 3\n",
    "start=time. time()\n",
    "dt_grid_parameters = {\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'splitter': ['random'],\n",
    "    'max_depth':[4, 3],\n",
    "    'min_samples_split': [2, 7, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32],\n",
    "    'min_samples_leaf': [1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
    "    'max_features': [100, 95, 90, 85, 80]\n",
    "}\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid=dt_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>random</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>0.8271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.8536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7876</td>\n",
       "      <td>0.8351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>96.0</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>0.8321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7844</td>\n",
       "      <td>0.8041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.8273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7803</td>\n",
       "      <td>0.8011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7802</td>\n",
       "      <td>0.8553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7796</td>\n",
       "      <td>0.8011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7777</td>\n",
       "      <td>0.8157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     criterion  max_depth  max_features  min_samples_leaf  min_samples_split  \\\n",
       "434       gini          4          90.0                13                 19   \n",
       "430       gini          4          90.0                12                 31   \n",
       "81        gini          4         100.0                18                 30   \n",
       "1402   entropy          4          96.0                16                 31   \n",
       "1927   entropy          3          98.0                18                 28   \n",
       "2337   entropy          3           NaN                17                 30   \n",
       "661       gini          3         100.0                18                  7   \n",
       "1740   entropy          4           NaN                17                  2   \n",
       "646       gini          3         100.0                16                 31   \n",
       "1119      gini          3           NaN                14                 20   \n",
       "\n",
       "     splitter  mean_score_validation  mean_score_training  \n",
       "434    random                 0.8055               0.8271  \n",
       "430    random                 0.7986               0.8536  \n",
       "81     random                 0.7876               0.8351  \n",
       "1402   random                 0.7870               0.8321  \n",
       "1927   random                 0.7844               0.8041  \n",
       "2337   random                 0.7826               0.8273  \n",
       "661    random                 0.7803               0.8011  \n",
       "1740   random                 0.7802               0.8553  \n",
       "646    random                 0.7796               0.8011  \n",
       "1119   random                 0.7777               0.8157  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.24762439727783\n"
     ]
    }
   ],
   "source": [
    "##### DT ITERATION 4\n",
    "start=time. time()\n",
    "dt_grid_parameters = {\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'splitter': ['random'],\n",
    "    'max_depth':[4, 3],\n",
    "    'min_samples_split': [2, 7, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32],\n",
    "    'min_samples_leaf': [12, 13, 14, 15, 16, 17, 18],\n",
    "    'max_features': [100, 98, 96, 94, 92, 90, None]\n",
    "}\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid=dt_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)\n",
    "\n",
    "#best_dt: criterion='gini', 'max_depth':4 , 'max_features' : 90, min_samples_leaf= 13,  min_samples_split= 19, splitter ='random'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El criterio Gini fue el mejor para construir el modelo. Por otro lado usar un mínimo de samples por hoja y para hacer split también sirvió. Creemos que de esta manera evitamos el sobre ajuste lo cual mejora el desempeño del modelo. De la misma manera contribuye limitar la profundidad máxima del arbol. Tambien se evidencia mejoras en el modelo utilizando baja profundidad maxima, esto ocurre ya que a mayor profundidad que a utilizada parece ocurrir overfitting, ademas encontramos  que usar un numero de features de aproximadamente 90, mejora la exactitud, o por lo menos no la perjudica, esto podria indicar que muchos de los atributos de nuestros minions no son relevantes a si son aptos o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.8103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7989</td>\n",
       "      <td>0.8247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7954</td>\n",
       "      <td>0.8109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7928</td>\n",
       "      <td>0.7869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>85</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7848</td>\n",
       "      <td>0.8520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.8218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>entropy</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7827</td>\n",
       "      <td>0.8617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7822</td>\n",
       "      <td>0.8391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.8101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7814</td>\n",
       "      <td>0.8256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     criterion  max_depth  max_features  min_samples_leaf  min_samples_split  \\\n",
       "1017   entropy          6            70                27                 33   \n",
       "1076   entropy          4            95                23                  9   \n",
       "1702      gini          7            80                29                 17   \n",
       "930    entropy          6            80                33                 35   \n",
       "142       gini          8            85                15                 13   \n",
       "1725      gini          4            85                25                 39   \n",
       "1578   entropy          9            85                15                 19   \n",
       "365    entropy          4            85                11                 35   \n",
       "690    entropy          4            95                25                 13   \n",
       "220       gini          5            65                19                  5   \n",
       "\n",
       "     splitter  mean_score_validation  mean_score_training  \n",
       "1017   random                 0.7990               0.8103  \n",
       "1076   random                 0.7989               0.8247  \n",
       "1702   random                 0.7954               0.8109  \n",
       "930    random                 0.7928               0.7869  \n",
       "142    random                 0.7848               0.8520  \n",
       "1725   random                 0.7835               0.8218  \n",
       "1578   random                 0.7827               0.8617  \n",
       "365    random                 0.7822               0.8391  \n",
       "690    random                 0.7820               0.8101  \n",
       "220    random                 0.7814               0.8256  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.461636543273926\n"
     ]
    }
   ],
   "source": [
    "#### DT usando randomized search\n",
    "start=time. time()\n",
    "dt_rsearch_parameters = {\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'splitter': ['random'],\n",
    "    'max_depth': np.arange(2,10),\n",
    "    'min_samples_split': np.arange(3,40,2),\n",
    "    'min_samples_leaf': np.arange(1,40,2),\n",
    "    'max_features': np.arange (50,100,5),\n",
    "}\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = RandomizedSearchCV(DecisionTreeClassifier(), param_distributions=dt_rsearch_parameters,n_iter=2000, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación entre grid y randomized search para DT\n",
    "\n",
    "No tuvimos en cuenta la iteración cero ya que era muy grosera por tener max depth none y max_features none. Comparamos con un randomized search usando rangos numéricos de los hiperparámetros que incluyan los testeados con el grid search en las otras iteraciones. Exceptuamos barrer grandes profundidades para evitar el sobreajuste, y limitamos el rango de min_samples_split y min_samples_leaf.\n",
    "\n",
    "Las diez iteraciones por default son demasiado pocas para tantas combinaciones de parámetros, y limitan mucho la búsqueda random. Dado que el espacio de combinaciones de hiperparámetros es tan alto (2x2x12x7x6=2016 en la it4), aumentamos las iteraciones hasta 2000 y achicamos el rango de hiperparámetros como describimos anteriormetne. Aún así el algoritmo random corrió un 37% más rápido que la iteración 4 y dio la mejor combinación dio un score de validación que la sitúa en segundo lugar respecto de los scores de validación de las combinaciones de la it 4 pero con un menor training score, lo cual podría indicar que generaliza mejor.\n",
    "\n",
    "Los resultados son distintos en que el mejor utiliza el criterio de entropia, y el mínimo de samples por hoja es mucho mayor en el mejor modelo encontrado por random search. Sí son parecidas la cantidad de features y el mínimo de samples para el split. Teniendo esta gran variación al modificar los hiperparámetros, creeríamos que hay que continuar incrementando las iteraciones del random search y achicando el step de los rangos de los hiperparámetros del modelo para definir regiones del espacio de parámetros con mayor score de validación (y training no demasido alto) y luego refinar en esas regiones con un grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore')\n",
    "##### LDA PARAMETERS\n",
    "start=time. time()\n",
    "lda_grid_parameters = [{\n",
    "    'solver': ['lsqr', 'eigen'], \n",
    "    'shrinkage': ['auto', 0.1, 0.25, 0.50, 0.75, 0.85, 0.9, 1.0],\n",
    "    'priors': [None, [0.3, 0.7], [0.4, 0.6], [0.5, 0.5], [0.6, 0.4], [0.7, 0.3] ]\n",
    "}, {\n",
    "    'solver': ['svd'], \n",
    "    'tol': [0.0, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "    'priors': [None, [0.3, 0.7], [0.4, 0.6], [0.5, 0.5], [0.6, 0.4], [0.7, 0.3] ]\n",
    "}]\n",
    "# svd no usa shrinkage, si  usa tol\n",
    "\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(LinearDiscriminantAnalysis(), param_grid=lda_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LDA ITERATION 1\n",
    "start=time. time()\n",
    "lda_grid_parameters = {\n",
    "    'solver': ['lsqr', 'eigen'], \n",
    "    'shrinkage': [0.65, 0.7, 0.75, 0.8, 0.85, 0.9],\n",
    "    'priors': [ None, [0.55, 0.45], [0.6, 0.4], [0.65, 0.35], [0.7, 0.3],\n",
    "               [0.75, 0.25], [0.8, 0.2], [0.85, 0.15], [0.9, 0.1] ]\n",
    "\n",
    "}\n",
    "    \n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(LinearDiscriminantAnalysis(), param_grid=lda_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### LDA ITERATION 2\n",
    "start=time. time()\n",
    "lda_grid_parameters = {\n",
    "    'solver': ['lsqr', 'eigen'], \n",
    "    'shrinkage': [0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85],\n",
    "    'priors': [[0.75, 0.25], [0.78, 0.22], [0.8, 0.2], [0.83, 0.17], [0.85, 0.15], [0.88, 0.12], [0.9, 0.1] ]\n",
    "\n",
    "}\n",
    "    \n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(LinearDiscriminantAnalysis(), param_grid=lda_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay diferencias al usar como solver a \"lsqr\" o \"eigen\", \"svd\" lo descartamos por que tuvo un bajo desempeño. Por otro lado el modelo mejora considerablemente  al condicionar los priors de proporciones de las clases y al asignarle un shrinkage. En el caso de las priors, encontramos extraño que mejore asignandole distribuciones lejanas a la registrada en la muestra(cercana al 50%), la cual tambien es la distribucion del conjunto de validacion, esto puede indicar que la distribucion original de minion no es la misma que presenta la muestra. Creemos que con shrinkage mejora ya que es posible que la cantidad de instancias sea baja en función de la cantidad de atributos de este set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LDA usando randomized search\n",
    "start=time. time()\n",
    "lda_rsearch_parameters = {\n",
    "\n",
    "}\n",
    "    \n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = RandomizedSearchCV(LinearDiscriminantAnalysis(), param_distributions=lda_rsearch_parameters, n_iter=1000, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación entre grid y randomized search para LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priors</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.95, 0.05]</td>\n",
       "      <td>0.8207</td>\n",
       "      <td>0.8687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.75, 0.25]</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.8684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.25, 0.75]</td>\n",
       "      <td>0.8201</td>\n",
       "      <td>0.8680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.8199</td>\n",
       "      <td>0.8685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>0.8199</td>\n",
       "      <td>0.8684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.05, 0.95]</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.8680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         priors  mean_score_validation  mean_score_training\n",
       "1  [0.95, 0.05]                 0.8207               0.8687\n",
       "2  [0.75, 0.25]                 0.8203               0.8684\n",
       "3  [0.25, 0.75]                 0.8201               0.8680\n",
       "4    [0.5, 0.5]                 0.8199               0.8685\n",
       "5          None                 0.8199               0.8684\n",
       "0  [0.05, 0.95]                 0.8193               0.8680"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Naive Bayes\n",
    "start=time. time()\n",
    "nb_grid_parameters = {\n",
    "    'priors': [[0.05, 0.95], [0.95, 0.05],[0.75, 0.25], [0.25, 0.75], [0.50, 0.50], None],\n",
    "}\n",
    "\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(GaussianNB(), param_grid=nb_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "start=time. time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos que la mejora obtenida por cambiar de prior=None a prior=[0.95, 0.05] es poca y no amerita realizar una suposición tan fuerte.\n",
    "La distribución de clases en la muestra que tenemos es cercana al 50%. Lo más parsimonioso es que este hiparámetro se determine a partir de la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NB usando randomized search\n",
    "start=time. time()\n",
    "nb_rsearch_parameters = {\n",
    "    'priors': [[0.05, 0.95], [0.95, 0.05],[0.75, 0.25], [0.25, 0.75], [0.50, 0.50], None],\n",
    "}\n",
    "\n",
    "#ver como hacer rangos con esta estructura para barrer mas opciones\n",
    "\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = RandomizedSearchCV(GaussianNB(), param_distributions=nb_rsearch_parameters, n_iter=10, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "start=time. time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación entre grid y randomized search para NB\n",
    "No tiene sentido hacer un randomized search cuando hay tan pocas combinaciones de parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Support Vector Classification para valores de C \"bajos\" [< 1 (default)]\n",
    "start=time. time()\n",
    "svc_grid_parameters ={\n",
    "    'C': [0.001, 0.1, 0.5],\n",
    "    'max_iter': [50, 250, 500, 1000, 1500, 2000],\n",
    "    'loss':['hinge', 'squared_hinge'],\n",
    "    'tol': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "    }\n",
    "\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(LinearSVC(), param_grid=svc_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Support Vector Classification para valores de C no muy \"bajos\" y \"altos\" [ > 1 (default)]\n",
    "start=time. time()\n",
    "svc_grid_parameters ={\n",
    "    'C': [0.1, 0.5, 0.75, 1, 1.50, 1.75],\n",
    "    'max_iter': [50, 250, 500, 1000, 1500, 2000], \n",
    "    'loss':['hinge', 'squared_hinge'],\n",
    "    'tol': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "    } \n",
    "\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(LinearSVC(), param_grid=svc_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SVC iter 1\n",
    "start=time. time()\n",
    "svc_grid_parameters ={\n",
    "    'C': [0.001, 0.005, 0.0005, 0.0001, 0.00001, 0.000001],\n",
    "    'max_iter': [50,100, 2000],\n",
    "    'loss':['hinge'],\n",
    "    'tol': [0.001, 0.01, 0.1, 0.2, 0.3, 0.4]\n",
    "    }\n",
    "\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(LinearSVC(), param_grid=svc_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por como se describe al parametro C en la documentación, a menores valores de C el hiperplano que separa las instancias es mas permisivo. Es decir permite errores de clasificación en los margenes cercanos al hiperplano. Creemos que los datos no pueden ser separados de manera perfecta con un hiperplano, ya que las instancias se encuentran muy mezcladas. Por eso es necesario aumentar la tolerancia. Los resultados obtenidos tambien podrian indicar que  nuestros atribitos son dependientes entre si, y que no siguen una distribucion normal. Lo que podria sugerir usar un preprocesamiento de nuestro datos, como por ejemplo PCA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SVC usando randomized search\n",
    "\n",
    "#SVC iter 1\n",
    "start=time. time()\n",
    "knn_rsearch_parameters ={\n",
    "    'C': [0.1, 0.5, 0.75, 1, 1.50, 1.75, 0.001, 0.005, 0.0005, 0.0001, 0.00001, 0.000001],\n",
    "    'max_iter': [50, 250, 500, 1000, 1500, 2000],\n",
    "    'loss':['hinge','squared_hinge'],\n",
    "    'tol': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2,0.001, 0.01, 0.1, 0.2, 0.3, 0.4]\n",
    "    }\n",
    "\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = RandomizedSearchCV(LinearSVC(), param_distributions=knn_rsearch_parameters,n_iter=2000, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)\n",
    "end = time. time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación entre grid y randomized search para SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: \n",
    "### Diagnóstico Sesgo-Varianza. \n",
    "\n",
    "En este punto, se pide inspeccionar dos de sus mejores modelos encontrados hasta ahora: el mejor modelo de tipo árbol de decisión y el mejor de tipo SVM. Para ello:\n",
    "\n",
    "1. Graficar curvas de complejidad para cada modelo, variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
    "2. Graficar curvas de aprendizaje para cada modelo. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
    "3. **Construir** un modelo RandomForest con 200 árboles. **Explorar** para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. **Explicar** por qué creen que se dieron los resultados obtenidos. Por último, **graficar** una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos (usar  grid search para encontrar una buena combinación de parámetros).  \n",
    "\n",
    "\n",
    "**Atención**: Tener en cuenta que debemos seguir utilizando ROC AUC como métrica para estas curvas.\n",
    "\n",
    "**ver**: http://scikit-learn.org/stable/modules/learning_curve.html#learning-curve\n",
    "\n",
    "----\n",
    "**EJERCICIO EXTRA:** Utilizar RandomizedSearchCV para explorar la performance del algoritmo de Gradient Boosting y comparar con los resultados obtenidos en el punto (c).\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para graficar curva de aprendizaje y curva de complejidad\n",
    "def plot_curve(title,param_name,param_range,train_scores_mean,train_scores_std,test_scores_mean,test_scores_std):\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0.0, 1.1)\n",
    "    lw = 2\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"navy\", lw=lw)\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=lw)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curvas de complejidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### Curvas de complejidad\n",
    "    #Para DT variando profundidad\n",
    "                                                    \n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "#shufflea con el seed de arriba, manteniendo proporciones de datos por fold.\n",
    "param_name='max_depth'\n",
    "param_range=[2,3,4,5,6,7,8,9,10,15,20,25,30,35,40,45, 50, 60, 70, 80, 90, 100, 120, 150, 200]\n",
    "cc_train_scores, cc_valid_scores = sklearn.model_selection.validation_curve(\n",
    "    DecisionTreeClassifier(criterion='gini', splitter ='random',min_samples_split=50, \n",
    "                           min_samples_leaf=2,max_features=None),X_dev_np, y_dev_np, \n",
    "    param_name=param_name, param_range=param_range, cv = cv, scoring='roc_auc')\n",
    "                                                    \n",
    "cc_train_scores_mean = np.mean(cc_train_scores, axis=1)\n",
    "cc_train_scores_std = np.std(cc_train_scores, axis=1)\n",
    "cc_test_scores_mean = np.mean(cc_valid_scores, axis=1)\n",
    "cc_test_scores_std = np.std(cc_valid_scores, axis=1)\n",
    "\n",
    "plot_curve(\"Curva de complejidad DT\",param_name,param_range,\n",
    "           cc_train_scores_mean,cc_train_scores_std,cc_test_scores_mean,cc_test_scores_std)\n",
    "\n",
    "##DT \n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "#shufflea con el seed de arriba, manteniendo proporciones de datos por fold.\n",
    "param_name='max_depth'\n",
    "param_range=[2,3,4,5,6,7,8,9,10,15,20,25,30]\n",
    "cc_train_scores, cc_valid_scores = sklearn.model_selection.validation_curve(\n",
    "    DecisionTreeClassifier(criterion='gini', splitter ='random',min_samples_split=50, \n",
    "                           min_samples_leaf=2,max_features=None),X_dev_np, y_dev_np, \n",
    "    param_name=param_name, param_range=param_range, cv = cv, scoring='roc_auc')\n",
    "                                                    \n",
    "cc_train_scores_mean = np.mean(cc_train_scores, axis=1)\n",
    "cc_train_scores_std = np.std(cc_train_scores, axis=1)\n",
    "cc_test_scores_mean = np.mean(cc_valid_scores, axis=1)\n",
    "cc_test_scores_std = np.std(cc_valid_scores, axis=1)\n",
    "\n",
    "plot_curve(\"Curva de complejidad DT - depth pequeñas\",param_name,param_range,\n",
    "           cc_train_scores_mean,cc_train_scores_std,cc_test_scores_mean,cc_test_scores_std)\n",
    "    #Para SVM variando C\n",
    "\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "#shufflea con el seed de arriba, manteniendo proporciones de datos por fold.\n",
    "param_name='C'\n",
    "param_range=[0.0001,0.0005,0.001,0.005, 0.01,0.05, 0.1, 0.5]\n",
    "cc_train_scores, cc_valid_scores = sklearn.model_selection.validation_curve(\n",
    "    LinearSVC(max_iter=2000, loss='hinge', tol=0.4),X_dev_np, y_dev_np,\n",
    "    param_name=param_name, param_range=param_range, cv = cv, scoring='roc_auc')\n",
    "                                                    \n",
    "cc_train_scores_mean = np.mean(cc_train_scores, axis=1)\n",
    "cc_train_scores_std = np.std(cc_train_scores, axis=1)\n",
    "cc_test_scores_mean = np.mean(cc_valid_scores, axis=1)\n",
    "cc_test_scores_std = np.std(cc_valid_scores, axis=1)\n",
    "\n",
    "plot_curve(\"Curva de complejidad SVM\",param_name,param_range,cc_train_scores_mean,cc_train_scores_std,\n",
    "           cc_test_scores_mean,cc_test_scores_std)\n",
    "\n",
    "#Svm en detalle\n",
    "\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "param_name='C'\n",
    "param_range=[0.00001,0.00005,0.0001,0.0002,0.0005,0.0008, 0.001, 0.002, 0.003, 0.005]\n",
    "cc_train_scores, cc_valid_scores = sklearn.model_selection.validation_curve(\n",
    "    LinearSVC(max_iter=2000, loss='hinge', tol=0.4),X_dev_np, y_dev_np,\n",
    "    param_name=param_name, param_range=param_range, cv = cv, scoring='roc_auc')\n",
    "                                                    \n",
    "cc_train_scores_mean = np.mean(cc_train_scores, axis=1)\n",
    "cc_train_scores_std = np.std(cc_train_scores, axis=1)\n",
    "cc_test_scores_mean = np.mean(cc_valid_scores, axis=1)\n",
    "cc_test_scores_std = np.std(cc_valid_scores, axis=1)\n",
    "\n",
    "plot_curve(\"Curva de complejidad SVM- C Pequeños\",param_name,param_range,cc_train_scores_mean,cc_train_scores_std,\n",
    "           cc_test_scores_mean,cc_test_scores_std)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de arboles a mayor profundidad (mayor complejidad) la varianza aumenta. Esto se evidencia en el aumento de la diferencia entre ambas curvas a medida. Por otro lado el sesgo disminuye a medida que aumenta la profundidad del arbol (observado como un training score mas alto).\n",
    "Esto evidencia que un arbol más profundo se ajusta muy bien a los datos de entrenamiento (bajo sesgo), pero no logra generalizar y falla al clasificar datos de validación (alta varianza). Y viceversa si es menos profundo. \n",
    "\n",
    "En el caso de SVM, vemos como el sesgo aumenta (menor training score) y la varianza disminuye (poca diferencia entre training score CV score) cuando el parametro C toma valores cercanos al cero. Contrariamente, a valores elevados de C, el sesgo disminuye y la varianza aumenta. Nos llama la atención que este resultado es contrario al que esperamos si tomamos en cuenta la definición y descripción del parámetro C dada en el libro **An Introduction to Statistical Learning with applications in R**. Aquí se describe a C como un parámetro que condiciona la permisividad de errores de clasificación en los margenes del hyperplano y mas allá de este. Entonces, a valores elevados del parámetro C se obtienen modelos con menor varianza.\n",
    "\n",
    "Como el parámetro C se define en la dcumentación como \"parámetro de penalidad del error\", creemos que en la implementación del algoritmo, C es la inversa del parámetro C descripto en el libro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curvas de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Curvas de aprendizaje\n",
    "#train_sizes, train_scores, valid_scores = learning_curve(\n",
    "#...     SVC(kernel='linear'), X, y, train_sizes=[50, 80, 110], cv=5)\n",
    "train_sizes=[2,3,4,5,6,7,8,9, 10,11,12,13,14,15,16,17,18,19, 20,21,22,25,26, 50, 75, 100,125, 150, 175, 200, 225, 250, 275, 300, 319]\n",
    "\n",
    "# \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Para DT\n",
    "\n",
    "#best_dt: criterion='gini', 'max_depth':4 , 'max_features' : 90, min_samples_leaf= 13,  min_samples_split= 19, splitter ='random'\n",
    "    \n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "#shufflea con el seed de arriba, manteniendo proporciones de datos por fold.\n",
    "ca_train_sizes, ca_train_scores, ca_valid_scores = sklearn.model_selection.learning_curve(DecisionTreeClassifier(\n",
    "    criterion='gini', splitter ='random', min_samples_split=19, min_samples_leaf=13,\n",
    "    max_features=90,max_depth=4), X_dev_np, y_dev_np, train_sizes=train_sizes, cv=cv, scoring='roc_auc')\n",
    "# min_samples_split=19, min_samples_leaf=13,\n",
    "    \n",
    "ca_train_scores_mean = np.mean(ca_train_scores, axis=1)\n",
    "ca_train_scores_std = np.std(ca_train_scores, axis=1)\n",
    "ca_test_scores_mean = np.mean(ca_valid_scores, axis=1)\n",
    "ca_test_scores_std = np.std(ca_valid_scores, axis=1)\n",
    "    \n",
    "plot_curve(\"Curva de aprendizaje DT\",'n',ca_train_sizes,ca_train_scores_mean,\n",
    "           ca_train_scores_std,ca_test_scores_mean,ca_test_scores_std)\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Para SVM\n",
    "    \n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "#shufflea con el seed de arriba, manteniendo proporciones de datos por fold.\n",
    "ca_train_sizes, ca_train_scores, ca_valid_scores = sklearn.model_selection.learning_curve(\n",
    "    LinearSVC(max_iter=50,C=0.001), X_dev_np, y_dev_np, train_sizes=train_sizes, cv=cv, scoring='roc_auc')\n",
    "    \n",
    "ca_train_scores_mean = np.mean(ca_train_scores, axis=1)\n",
    "ca_train_scores_std = np.std(ca_train_scores, axis=1)\n",
    "ca_test_scores_mean = np.mean(ca_valid_scores, axis=1)\n",
    "ca_test_scores_std = np.std(ca_valid_scores, axis=1)\n",
    "    \n",
    "plot_curve(\"Curva de aprendizaje SVM\",'n',train_sizes,ca_train_scores_mean,ca_train_scores_std,\n",
    "           ca_test_scores_mean,ca_test_scores_std)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de DT, las curvas de aprendizaje se estabilizan luego de que la muestra supera las 50 instacias (aprox). Para $n < 26$, por los hiperparámetros elegidos, no puede generar un árbol de más de un nodo entonces no logra clasificar en más de una categoría y el score es de 0.5.  \n",
    "Por otro lado, para el caso de  SVM la curva de aprendizaje (para el CV) llega a un pateau cuando el $n > 10$.\n",
    "Si bien parece haber una leve tendencia de aumento en las curvas de CV, como el error es grande, consideramos que la performance de ambos modelos no aumenta: parecen haber alcanzado su límite. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#RandomForest\n",
    "    # Construyo con 200 árboles\n",
    "    # Veo desempeño modelo con cross-validation\n",
    "\n",
    "    #Curva de complejidad variando max_features\n",
    "    #Curva de aprendizaje\n",
    "    \n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "#shufflea con el seed de arriba, manteniendo proporciones de datos por fold.\n",
    "rForest = RandomForestClassifier(n_estimators = 200)\n",
    "scores = sklearn.model_selection.cross_validate(rForest, X_dev_np, y_dev_np, cv = cv,\n",
    "                                                scoring='roc_auc', return_train_score=True)\n",
    "\n",
    "\n",
    "# Hago tabla con resultados del CV\n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "df[\"AUC ROC (training)\"] = scores['train_score']     \n",
    "df[\"AUC ROC (validación)\"] = scores['test_score']    \n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "print(\"Media AUC-ROC (validación): {}\".format(np.mean(scores['test_score'] )))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Que pasa si variamos **max_features**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest variando 'max_features'\n",
    "\n",
    "rForest_grid_parameters ={\n",
    "    'max_features' : ['sqrt','log2',1, 2, 5, 10, 20, 30, 40, 50, 100, 125, 150, 175, None], \n",
    "    'n_estimators': [10, 50, 100, 200]\n",
    "}\n",
    "\n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid= rForest_grid_parameters, cv=cv, scoring='roc_auc')\n",
    "grid.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un mejor resultado si limitamos **'max_features' = 50 **.\n",
    "\n",
    "Pero ¿cómo afecta este parámetro a la curva de complejidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### Curva de complejidad para Random Forest variando 'max_features'\n",
    "                                                    \n",
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True) \n",
    "#shufflea con el seed de arriba, manteniendo proporciones de datos por fold.\n",
    "param_name='max_features'\n",
    "param_range= [1, 2, 5, 7, 14, 20, 30, 40, 50, 60, 70, 100]\n",
    "cc_train_scores, cc_valid_scores = sklearn.model_selection.validation_curve(RandomForestClassifier(n_estimators = 10),\n",
    "                                                                            X_dev_np, y_dev_np, \n",
    "                                                                            param_name=param_name, param_range=param_range,\n",
    "                                                                            cv = cv, scoring='roc_auc')\n",
    "                                                    \n",
    "cc_train_scores_mean = np.mean(cc_train_scores, axis=1)\n",
    "cc_train_scores_std = np.std(cc_train_scores, axis=1)\n",
    "cc_test_scores_mean = np.mean(cc_valid_scores, axis=1)\n",
    "cc_test_scores_std = np.std(cc_valid_scores, axis=1)\n",
    "\n",
    "plot_curve(\"Curva de complejidad Random Forest\",param_name,param_range,cc_train_scores_mean,cc_train_scores_std,cc_test_scores_mean,cc_test_scores_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico se puede ver que variar el parámetro **max_features** no produce grandes cambios en la performance del modelo. Esto podría ser debido a que con una cantidad tan grande de árboles, aún si estos tienen pocas features, andan muy bien. La curva de complejidad se mantiene \"chata\" y parece decrecer monotamente apartir de 70. Igualmente usando **max_features = 50** se obtiene el máximo **mean_score_validation** (AUC ROC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curva de aprendizaje para Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5 , shuffle=True)\n",
    "train_sizes=[10,25, 50, 75, 100,125, 150, 175, 200, 225, 250, 275, 300, 319]\n",
    "#shufflea con el seed de arriba, manteniendo proporciones de datos por fold.\n",
    "ca_train_sizes, ca_train_scores, ca_valid_scores = sklearn.model_selection.learning_curve(\n",
    "    RandomForestClassifier(n_estimators = 200, max_features = 50), X_dev_np, y_dev_np, \n",
    "    train_sizes=train_sizes, cv=cv, scoring='roc_auc')\n",
    "    \n",
    "ca_train_scores_mean = np.mean(ca_train_scores, axis=1)\n",
    "ca_train_scores_std = np.std(ca_train_scores, axis=1)\n",
    "ca_test_scores_mean = np.mean(ca_valid_scores, axis=1)\n",
    "ca_test_scores_std = np.std(ca_valid_scores, axis=1)\n",
    "    \n",
    "plot_curve(\"Curva de aprendizaje Random Forest\",'n',ca_train_sizes,ca_train_scores_mean,ca_train_scores_std,\n",
    "           ca_test_scores_mean,ca_test_scores_std)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No necesitamos aumentar la cantidad de datos ya que la curva de aprendizaje llega a un plateau cuando $50<n<100$ (aprox.) y los folds que son usados para entrenar los modelos tienen $n = 320$. Inclusive apartir de $n=300$, parece volverse constante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "svm = LinearSVC(C=0.001, loss='hinge', max_iter=100, tol=0.4)\n",
    "rf = RandomForestClassifier(n_estimators = 50, max_features = 'sqrt')\n",
    "lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=0.82, priors=[0.88, 0.12])\n",
    "knn = KNeighborsClassifier(n_neighbors=83, weights='uniform', p=1)\n",
    "\n",
    "X_eval_np = np.array(X_eval)\n",
    "y_eval_np = np.array(y_eval).ravel()\n",
    "\n",
    "svm.fit(X_dev_np, y_dev_np)\n",
    "svm_predict = svm.predict(X_eval_np)\n",
    "roc_svm = roc_auc_score(y_eval_np, svm_predict)\n",
    "\n",
    "rf.fit(X_dev_np, y_dev_np)\n",
    "rf_predict = rf.predict(X_eval_np)\n",
    "roc_rf = roc_auc_score(y_eval_np, rf_predict)\n",
    "\n",
    "lda.fit(X_dev_np, y_dev_np)\n",
    "lda_predict = lda.predict(X_eval_np)\n",
    "roc_lda = roc_auc_score(y_eval_np, lda_predict)\n",
    "\n",
    "knn.fit(X_dev_np, y_dev_np)\n",
    "knn_predict = knn.predict(X_eval_np)\n",
    "roc_knn = roc_auc_score(y_eval_np, knn_predict)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(index=range(1,5))\n",
    "df.index.name = \"Modelo\"\n",
    "                  \n",
    "df[\"Modelo\"] = [\"SVM\", \"Random Forest\", \"LDA\", \"KNN\"]     # cambiar por accuracies_training\n",
    "df[\"AUC ROC\"] = [roc_svm, roc_rf, roc_lda, roc_knn]\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_competencia_np =np.array(X_competencia)\n",
    "\n",
    "comp_rf_pred = rf.predict_proba(X_competencia_np)\n",
    "comp_rf_pred_np = np.array(comp_rf_pred)[:,1]\n",
    "idx = range(501, 501+len(comp_rf_pred_np))\n",
    "res = np.zeros((len(idx), 2))\n",
    "for i in range(len(idx)):\n",
    "    res[i][0] = idx[i]\n",
    "    res[i][1] = comp_rf_pred_np[i]\n",
    "np.savetxt('y_competencia.csv', res, delimiter=',', fmt='%.4f' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competencias\n",
    "\n",
    "La entrega del trabajo estará acompañada de una competencia en la cual deberán poner a prueba su mejor modelo y sobre todo, su capacidad para estimar sus resultados. \n",
    "\n",
    "Su tarea será estimar la performance (AUC ROC) que tendrá su mejor modelo en datos de evaluación (X_competencia). \n",
    "\n",
    "Para ello, deberán predecir las probabilidades de las distintas instancias con su modelo, enviarnos dichas probabilidades junto a una estimación con 4 decimales de cuál será el AUC ROC resultante y calcularemos el resultado real. El grupo que consiga acercarse más al valor real, será el grupo ganador.  \n",
    "\n",
    "Recomendamos no perder de vista esta competencia en el momento de separar los datos en los primeros puntos. \n",
    "\n",
    "Para esto, junto con la entrega del informe, deberán enviar un archivo en formato csv con las columnas “index” y “output” (ver ejemplo de archivo en: [y_competencia_ejemplo.csv](https://github.com/pbrusco/aa-notebooks/blob/master/TP1/y_competencia_ejemplo.csv)) y un valor esperado de AUC ROC. \n",
    "\n",
    "\n",
    "## Entrega\n",
    "- Contarán con un esqueleto en formato Jupyter Notebook en donde tendrán que completar las celdas faltantes (ya sea con explicaciones y gráficos o código). \n",
    "- El notebook final deberá ser entregado en formatos .html e .ipynb. Es necesario que los resultados puedan reproducirse al ejecutar todas las celdas en orden (Kernel - Restart and Run All) utilizando las bibliotecas requeridas en el archivo: requirements.txt del repositorio. \n",
    "- Tienen tiempo hasta las 23:59hs del día miércoles 17/10/2018. La entrega se debe realizar a través del campus virtual y debe contener el informe.\n",
    "- El trabajo deberá elaborarse en grupos de 3 personas.\n",
    "- Se podrán pedir pruebas de integridad y autoría; es decir, verificar que la salida solicitada es fruto del modelo presentado y que el modelo fue construido según lo requerido en este enunciado.\n",
    "- La evaluación será grupal y se basará en la calidad del informe (presentación, claridad, prolijidad); la originalidad, practicidad y coherencia técnica de la solución; la corrección y solidez de las pruebas realizadas.\n",
    "- En el primer parcial se incluirá una pregunta sobre la solución entregada. Esa pregunta no influirá en la nota del parcial, pero sí en la nota individual del TP1.\n",
    "- La participación en la competencia es obligatoria. De todas maneras, el resultado no incidirán en la nota de la materia.\n",
    "- Los ejercicios extra son opcionales para aprobar el TP, pero son obligatorios para promocionar la materia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Competencia\n",
    "\n",
    "El mejor modelo de los que exploramos es RandomForestClassifier con $n$_$estimators=50$ y $max$_$features=sqrt$, obtuvo un AUC ROC estimado de 0.7351."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
